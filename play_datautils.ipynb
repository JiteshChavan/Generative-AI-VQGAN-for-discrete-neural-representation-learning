{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_Utils testrun\n",
    "- Preprocess imagesin in RawTest, store to pre_procced\n",
    "- normalize images in pre_procced and store to test_shards\n",
    "- load shard from test_shards and reconstruct in folder \"recons\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 Images Processed and saved to: ./dummy tests/pre_procced (assuming all were images in the 3 supported format)\n",
      "Saved shard 000 with remaining images.\n",
      "All images processed and saved in ./dummy tests/test_shards.\n"
     ]
    }
   ],
   "source": [
    "from data_utils import Data_Utils_Config, DataUtils\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def load_tokens (filename):\n",
    "    npt = np.load (filename)\n",
    "    ptt = torch.from_numpy (npt).permute (0, 3, 1, 2)\n",
    "    return ptt\n",
    "\n",
    "data_util = DataUtils (Data_Utils_Config(downscale_res=256))\n",
    "data_util.preprocess_images_in_folder (\"./dummy tests/RawTest\", dest=\"./dummy tests/pre_procced\")\n",
    "data_util.normalized_images_to_shards (\"./dummy tests/pre_procced\", dest_shards=\"./dummy tests/test_shards\", shard_batch_size=640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading shard ./dummy tests/test_shards\\images_batch_000.npy\n",
      "torch.float16 torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "src_shards = \"./dummy tests/test_shards\"\n",
    "shards = []\n",
    "shards = (os.listdir(src_shards))\n",
    "\n",
    "\n",
    "\n",
    "for i, shard in enumerate(shards):\n",
    "    shard_path = os.path.join (src_shards, shard)\n",
    "    print (f\"loading shard {shard_path}\")\n",
    "    tokens = load_tokens (shard_path)\n",
    "    print (tokens.dtype, tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved ./dummy tests/recons/neural_recon_0000.png\n",
      "saved ./dummy tests/recons/neural_recon_0001.png\n",
      "saved ./dummy tests/recons/neural_recon_0002.png\n",
      "saved ./dummy tests/recons/neural_recon_0003.png\n",
      "saved ./dummy tests/recons/neural_recon_0004.png\n",
      "saved ./dummy tests/recons/neural_recon_0005.png\n",
      "saved ./dummy tests/recons/neural_recon_0006.png\n",
      "saved ./dummy tests/recons/neural_recon_0007.png\n",
      "saved ./dummy tests/recons/neural_recon_0008.png\n",
      "saved ./dummy tests/recons/neural_recon_0009.png\n",
      "saved ./dummy tests/recons/neural_recon_0010.png\n",
      "saved ./dummy tests/recons/neural_recon_0011.png\n",
      "saved ./dummy tests/recons/neural_recon_0012.png\n",
      "saved ./dummy tests/recons/neural_recon_0013.png\n",
      "saved ./dummy tests/recons/neural_recon_0014.png\n",
      "saved ./dummy tests/recons/neural_recon_0015.png\n"
     ]
    }
   ],
   "source": [
    "data_util.tensor_to_image (tokens, \"./dummy tests/recons\", \"neural_recon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
