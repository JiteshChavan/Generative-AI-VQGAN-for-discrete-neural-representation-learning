{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from discriminator import Discriminator, DiscriminatorConfig\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "a = torch.ones (1, 3, 256, 256)\n",
    "\n",
    "disc = Discriminator (DiscriminatorConfig)\n",
    "\n",
    "\n",
    "disc_optimizer = torch.optim.AdamW (disc.parameters(), lr= 6e-4, betas=(0.9,0.95), eps=1e-8)\n",
    "disc_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "loss = torch.mean(disc (a))\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {pn:p for pn,p in disc.named_parameters()}\n",
    "\n",
    "current_gradients = [param.grad.clone() if param.grad is not None else None for param in disc.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pn, p in disc.named_parameters():\n",
    "    assert p.grad is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_conv.weight\n",
      "in_conv.bias\n",
      "model.1.weight\n",
      "model.1.bias\n",
      "model.2.group_norm.weight\n",
      "model.2.group_norm.bias\n",
      "model.4.weight\n",
      "model.4.bias\n",
      "model.5.group_norm.weight\n",
      "model.5.group_norm.bias\n",
      "model.7.weight\n",
      "model.7.bias\n",
      "model.8.group_norm.weight\n",
      "model.8.group_norm.bias\n",
      "model.10.weight\n",
      "model.10.bias\n"
     ]
    }
   ],
   "source": [
    "for k in param_dict.keys():\n",
    "    print (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[[[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
      "\n",
      "         [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
      "\n",
      "         [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]]],\n",
      "\n",
      "\n",
      "        [[[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
      "\n",
      "         [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
      "\n",
      "         [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]]],\n",
      "\n",
      "\n",
      "        [[[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
      "\n",
      "         [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
      "\n",
      "         [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
      "\n",
      "         [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
      "\n",
      "         [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
      "\n",
      "         [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
      "\n",
      "         [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
      "\n",
      "         [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
      "\n",
      "         [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]]]])\n"
     ]
    }
   ],
   "source": [
    "print(param_dict[\"in_conv.weight\"].grad)\n",
    "print (current_gradients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param, grad_copy in zip (disc.parameters(), current_gradients):\n",
    "    if grad_copy is not None:\n",
    "        param.grad = grad_copy.clone()\n",
    "    else :\n",
    "        param.grad = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict[\"in_conv.weight\"].grad.allclose (current_gradients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
      "\n",
      "         [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
      "\n",
      "         [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
      "          [ 0.0564,  0.0578,  0.0578,  0.0575]]],\n",
      "\n",
      "\n",
      "        [[[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
      "\n",
      "         [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
      "\n",
      "         [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1182, -0.1164, -0.1164, -0.1163],\n",
      "          [-0.1159, -0.1140, -0.1140, -0.1140]]],\n",
      "\n",
      "\n",
      "        [[[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
      "\n",
      "         [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
      "\n",
      "         [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0141, -0.0131, -0.0131, -0.0127],\n",
      "          [-0.0159, -0.0149, -0.0149, -0.0145]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
      "\n",
      "         [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
      "\n",
      "         [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0388, -0.0385, -0.0385, -0.0375],\n",
      "          [-0.0396, -0.0392, -0.0392, -0.0383]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
      "\n",
      "         [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
      "\n",
      "         [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
      "          [ 0.0174,  0.0176,  0.0176,  0.0140]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
      "\n",
      "         [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
      "\n",
      "         [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
      "          [ 0.0260,  0.0256,  0.0256,  0.0234]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([[[[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
       " \n",
       "          [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0564,  0.0578,  0.0578,  0.0575]],\n",
       " \n",
       "          [[ 0.0595,  0.0609,  0.0609,  0.0607],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0590,  0.0604,  0.0604,  0.0601],\n",
       "           [ 0.0564,  0.0578,  0.0578,  0.0575]]],\n",
       " \n",
       " \n",
       "         [[[-0.1191, -0.1172, -0.1172, -0.1172],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
       " \n",
       "          [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1159, -0.1140, -0.1140, -0.1140]],\n",
       " \n",
       "          [[-0.1191, -0.1172, -0.1172, -0.1172],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1182, -0.1164, -0.1164, -0.1163],\n",
       "           [-0.1159, -0.1140, -0.1140, -0.1140]]],\n",
       " \n",
       " \n",
       "         [[[-0.0163, -0.0154, -0.0154, -0.0149],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
       " \n",
       "          [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0159, -0.0149, -0.0149, -0.0145]],\n",
       " \n",
       "          [[-0.0163, -0.0154, -0.0154, -0.0149],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0141, -0.0131, -0.0131, -0.0127],\n",
       "           [-0.0159, -0.0149, -0.0149, -0.0145]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0378, -0.0374, -0.0374, -0.0364],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
       " \n",
       "          [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0396, -0.0392, -0.0392, -0.0383]],\n",
       " \n",
       "          [[-0.0378, -0.0374, -0.0374, -0.0364],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0388, -0.0385, -0.0385, -0.0375],\n",
       "           [-0.0396, -0.0392, -0.0392, -0.0383]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
       " \n",
       "          [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0174,  0.0176,  0.0176,  0.0140]],\n",
       " \n",
       "          [[ 0.0195,  0.0196,  0.0196,  0.0160],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0204,  0.0206,  0.0206,  0.0170],\n",
       "           [ 0.0174,  0.0176,  0.0176,  0.0140]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
       " \n",
       "          [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0260,  0.0256,  0.0256,  0.0234]],\n",
       " \n",
       "          [[ 0.0262,  0.0257,  0.0257,  0.0235],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0254,  0.0250,  0.0250,  0.0227],\n",
       "           [ 0.0260,  0.0256,  0.0256,  0.0234]]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(param_dict[\"in_conv.weight\"].grad), current_gradients[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m disc\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[1;32m----> 2\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "a = [p for p in disc.parameters()]\n",
    "b = torch.tensor([a.grad for a in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcurrent_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m, b\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "current_gradients.shape\n",
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (4) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     current_gradients \u001b[38;5;241m=\u001b[39m [param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m disc\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     current_gradients \u001b[38;5;241m=\u001b[39m [grad \u001b[38;5;241m+\u001b[39m param_grad \u001b[38;5;28;01mfor\u001b[39;00m grad, param_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m (current_gradients, param\u001b[38;5;241m.\u001b[39mgrad)]\n",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m     current_gradients \u001b[38;5;241m=\u001b[39m [param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m disc\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m----> 5\u001b[0m     current_gradients \u001b[38;5;241m=\u001b[39m [\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparam_grad\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m grad, param_grad \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m (current_gradients, param\u001b[38;5;241m.\u001b[39mgrad)]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (4) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "for param in disc.parameters ():\n",
    "    if micro_step == 0:\n",
    "        current_gradients = [param.grad.clone() if param.grad is not None else None for param in disc.parameters()]\n",
    "    else:\n",
    "\n",
    "        current_gradients = [grad + param_grad for grad, param_grad in zip (current_gradients, param.grad)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from discriminator import Discriminator, DiscriminatorConfig\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "a = torch.ones (1, 3, 256, 256)\n",
    "\n",
    "disc = Discriminator (DiscriminatorConfig)\n",
    "\n",
    "\n",
    "disc_optimizer = torch.optim.AdamW (disc.parameters(), lr= 6e-4, betas=(0.9,0.95), eps=1e-8)\n",
    "disc_optimizer.zero_grad()\n",
    "\n",
    "\n",
    "loss = torch.mean(disc (a))\n",
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vqgan.zero\n",
    "# vqganbackward\n",
    "# disc.zero\n",
    "# dlossbackward\n",
    "# safe <- clone\n",
    "# safe += \n",
    "reference = [p.grad.clone() for p in disc.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range (2):\n",
    "    if step == 0:\n",
    "        safe_grad = [p.grad.clone() for i,p in enumerate(disc.parameters())]\n",
    "    else:\n",
    "        for i, p in enumerate (disc.parameters()):\n",
    "            safe_grad[i] += p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(reference)):\n",
    "    print(reference[i].allclose(0.5 * safe_grad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in (enumerate(disc.parameters())):\n",
    "    p.grad = safe_grad[i].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_conv.weight\n",
      "in_conv.bias\n",
      "model.1.weight\n",
      "model.1.bias\n",
      "model.2.group_norm.weight\n",
      "model.2.group_norm.bias\n",
      "model.4.weight\n",
      "model.4.bias\n",
      "model.5.group_norm.weight\n",
      "model.5.group_norm.bias\n",
      "model.7.weight\n",
      "model.7.bias\n",
      "model.8.group_norm.weight\n",
      "model.8.group_norm.bias\n",
      "model.10.weight\n",
      "model.10.bias\n"
     ]
    }
   ],
   "source": [
    "param_dict = {pn:p for pn,p in disc.named_parameters()}\n",
    "for k in param_dict.keys():\n",
    "    print (k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1190,  0.1218,  0.1218,  0.1214],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1127,  0.1155,  0.1155,  0.1151]],\n",
       "\n",
       "         [[ 0.1190,  0.1218,  0.1218,  0.1214],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1127,  0.1155,  0.1155,  0.1151]],\n",
       "\n",
       "         [[ 0.1190,  0.1218,  0.1218,  0.1214],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1179,  0.1207,  0.1207,  0.1203],\n",
       "          [ 0.1127,  0.1155,  0.1155,  0.1151]]],\n",
       "\n",
       "\n",
       "        [[[-0.2383, -0.2345, -0.2345, -0.2344],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2318, -0.2281, -0.2281, -0.2281]],\n",
       "\n",
       "         [[-0.2383, -0.2345, -0.2345, -0.2344],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2318, -0.2281, -0.2281, -0.2281]],\n",
       "\n",
       "         [[-0.2383, -0.2345, -0.2345, -0.2344],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2365, -0.2328, -0.2328, -0.2327],\n",
       "          [-0.2318, -0.2281, -0.2281, -0.2281]]],\n",
       "\n",
       "\n",
       "        [[[-0.0326, -0.0307, -0.0307, -0.0298],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0317, -0.0299, -0.0299, -0.0289]],\n",
       "\n",
       "         [[-0.0326, -0.0307, -0.0307, -0.0298],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0317, -0.0299, -0.0299, -0.0289]],\n",
       "\n",
       "         [[-0.0326, -0.0307, -0.0307, -0.0298],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0282, -0.0263, -0.0263, -0.0254],\n",
       "          [-0.0317, -0.0299, -0.0299, -0.0289]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0756, -0.0748, -0.0748, -0.0729],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0792, -0.0785, -0.0785, -0.0766]],\n",
       "\n",
       "         [[-0.0756, -0.0748, -0.0748, -0.0729],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0792, -0.0785, -0.0785, -0.0766]],\n",
       "\n",
       "         [[-0.0756, -0.0748, -0.0748, -0.0729],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0777, -0.0769, -0.0769, -0.0751],\n",
       "          [-0.0792, -0.0785, -0.0785, -0.0766]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0390,  0.0392,  0.0392,  0.0321],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0349,  0.0351,  0.0351,  0.0280]],\n",
       "\n",
       "         [[ 0.0390,  0.0392,  0.0392,  0.0321],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0349,  0.0351,  0.0351,  0.0280]],\n",
       "\n",
       "         [[ 0.0390,  0.0392,  0.0392,  0.0321],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0409,  0.0412,  0.0412,  0.0340],\n",
       "          [ 0.0349,  0.0351,  0.0351,  0.0280]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0524,  0.0515,  0.0515,  0.0470],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0520,  0.0512,  0.0512,  0.0467]],\n",
       "\n",
       "         [[ 0.0524,  0.0515,  0.0515,  0.0470],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0520,  0.0512,  0.0512,  0.0467]],\n",
       "\n",
       "         [[ 0.0524,  0.0515,  0.0515,  0.0470],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0508,  0.0499,  0.0499,  0.0454],\n",
       "          [ 0.0520,  0.0512,  0.0512,  0.0467]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict[\"in_conv.weight\"].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reference[0].allclose(0.5 * param_dict[\"in_conv.weight\"].grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
